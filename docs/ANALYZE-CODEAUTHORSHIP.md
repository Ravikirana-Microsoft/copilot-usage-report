# Analyze-CodeAuthorship.ps1 Documentation

## Overview

The `Analyze-CodeAuthorship.ps1` script analyzes Git commit history to determine the percentage of code that was AI-assisted (e.g., GitHub Copilot) versus human-written. It uses a sophisticated **5-tier weighted pattern detection model** to classify commits with varying confidence levels.

---

## Usage

```powershell
# Basic usage
.\Analyze-CodeAuthorship.ps1 -RepoPath "C:\repos\myapp" -ApplicationName "MyApp" -Branch "main"

# With date range
.\Analyze-CodeAuthorship.ps1 -RepoPath "C:\repos\myapp" -ApplicationName "MyApp" -Branch "main" -StartDate "2025-09-01" -EndDate "2026-01-07"

# Incremental analysis (merge with previous data)
.\Analyze-CodeAuthorship.ps1 -RepoPath "C:\repos\myapp" -ApplicationName "MyApp" -Branch "main" -PreviousDataPath "reports\archive\Analysis.json"
```

---

## Parameters

| Parameter | Required | Description |
|-----------|----------|-------------|
| `RepoPath` | Yes | Path to the Git repository to analyze |
| `ApplicationName` | Yes | Name of the application (used for report folder naming) |
| `Branch` | Yes | Git branch to analyze |
| `StartDate` | No | Start date for analysis (format: yyyy-MM-dd) |
| `EndDate` | No | End date for analysis (format: yyyy-MM-dd) |
| `OutputPath` | No | Path where reports will be saved (default: `../reports`) |
| `PreviousDataPath` | No | Path to previous analysis JSON for incremental mode |

---

## How It Works

### High-Level Flow

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      Analyze-CodeAuthorship.ps1                              │
│  For each repository:                                                        │
│  1. Fetch git log with --numstat (commit + file changes)                    │
│  2. Parse each commit (hash, author, date, message, files)                  │
│  3. For each commit, apply 5-Tier AI detection                              │
│  4. Aggregate by user and calculate percentages                             │
│  5. Generate JSON, CSV, and Markdown reports                                │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Step 1: Repository Sync

The script first syncs the repository to ensure it has the latest commits:

```powershell
git fetch --all --prune
git checkout $Branch
git pull origin $Branch
```

### Step 2: Fetch Commit History

Uses git log with `--numstat` to get commit details and line changes:

```powershell
git log $Branch --no-merges --numstat --pretty=format:'COMMIT:%H|%an|%ae|%ad|%s'
```

- `--no-merges`: Excludes merge commits (only actual code commits)
- `--numstat`: Shows lines added/deleted per file
- `--pretty=format`: Custom format with hash, author, email, date, message

**Example output:**
```
COMMIT:abc123|Ravi|ravi@microsoft.com|Jan 15 2026|feat: Add Redux store
5       2       src/store/chatSlice.ts
10      0       src/components/Chat.tsx
```

### Step 3: Parse Commits

Each commit is parsed into a structured object:

```powershell
$commit = [PSCustomObject]@{
    Hash = "abc123"
    Author = "Ravi"
    Email = "ravi@microsoft.com"
    Date = "Jan 15 2026"
    Message = "feat: Add Redux store"
    Files = @(...)  # Array of file changes
    LinesAdded = 15
    LinesDeleted = 2
    IsAI = $false   # Will be determined by 5-Tier analysis
    ConfidenceScore = 0
    ConfidenceTier = "Human Written"
    TierNumber = 0
}
```

### Step 4: AI Pattern Detection

For each commit, the script:
1. Fetches the actual diff content using `git diff-tree`
2. Scans for AI-indicative patterns across 5 tiers
3. Calculates a weighted score
4. Determines confidence level

### Step 5: Generate Reports

Outputs include:
- **JSON**: Complete data with all commits and user stats
- **CSV**: Summary tables for Excel analysis
- **Markdown**: Human-readable report

---

## 5-Tier AI Detection Model

The script uses a weighted pattern matching system where each tier represents a different confidence level.

### Tier Overview

| Tier | Confidence | Description | How Detected |
|------|------------|-------------|--------------|
| **Tier 1** | 99-100% | Definitive AI | Explicit markers like `Co-authored-by: Copilot` |
| **Tier 2** | 90-98% | Very High | Strong AI code patterns (verbose, comprehensive) |
| **Tier 3** | 80-89% | High | Common AI patterns (async, error handling) |
| **Tier 4** | 70-79% | Moderate | Modern syntax patterns |
| **Tier 5** | 60-69% | Low | Weak indicators (need many matches) |
| **Human** | <60% | No AI | Below threshold or no patterns |

---

### Tier 1: Definitive AI (99-100%) — Weight: 100

Explicit markers that definitively indicate AI involvement:

| Pattern | Description |
|---------|-------------|
| `GitHub Copilot` | Direct Copilot mention |
| `Generated by Copilot` | Explicit generation marker |
| `Co-authored-by:.*[Cc]opilot` | Git trailer with Copilot |
| `[AI]`, `[copilot]` | AI tags in commit message |
| `# AI generated`, `// copilot` | Code comments |
| `auto-generated` | Auto-generation marker |
| `@ai-assisted`, `AI-generated` | Explicit AI markers |

**Example Match:**
```
commit abc123
Author: Ravi <ravi@microsoft.com>
Date: Jan 15 2026

feat: Add authentication module

Co-authored-by: GitHub Copilot <copilot@github.com>  ← TIER 1 MATCH
```

---

### Tier 2: Very High Confidence (90-98%) — Weight: 15-25

Strong AI signatures that humans rarely write this way:

| Pattern | Weight | Description |
|---------|--------|-------------|
| `// [A-Z][a-z]+ the \w+ (to\|from\|for\|with)` | 20 | AI-style verbose comments |
| `try {...} catch {...} finally` | 18 | Comprehensive error handling |
| `ArgumentNullException.*nameof` | 15 | Parameter validation |
| `string.IsNullOrEmpty...throw` | 18 | Null checking with throw |
| `$result\d+`, `$response\d+` | 15 | AI placeholder naming |
| `.ConfigureAwait(false)` | 15 | Async best practice |
| `createAsyncThunk\(` | 18 | Redux Toolkit async |
| `extraReducers: (builder)` | 20 | Redux Toolkit pattern |
| `.addCase(\w+.(pending\|fulfilled\|rejected)` | 15 | Redux state handling |
| `createSlice\({` | 15 | Redux slice creation |

**Example AI Code (Tier 2):**
```typescript
// Initialize the async thunk for fetching user data  ← AI-style comment
export const fetchUserData = createAsyncThunk(       ← Redux pattern
    'user/fetchData',
    async (userId: string, { rejectWithValue }) => {
        try {
            const response = await api.getUser(userId);
            return response.data;
        } catch (error) {
            return rejectWithValue(error.message);   ← Comprehensive error handling
        }
    }
);

const userSlice = createSlice({
    name: 'user',
    initialState,
    extraReducers: (builder) => {                    ← Builder pattern
        builder
            .addCase(fetchUserData.pending, ...)     ← addCase pattern
            .addCase(fetchUserData.fulfilled, ...)
            .addCase(fetchUserData.rejected, ...);
    }
});
```

---

### Tier 3: High Confidence (80-89%) — Weight: 8-14

Patterns suggesting AI but could be experienced developers:

| Pattern | Weight | Description |
|---------|--------|-------------|
| `catch (Exception \w+) {...throw;}` | 12 | Structured exception handling |
| `?? throw new` | 10 | Null coalescing with throw |
| `await Task.WhenAll` | 10 | Parallel async |
| `await Task.WhenAny` | 10 | Competitive async |
| `async Task<T> \w+Async(` | 8 | Async naming convention |
| `useCallback<T>(` | 10 | React hooks with generics |
| `useMemo<T>(` | 10 | React memoization |
| `React.FC<\w+Props>` | 8 | React functional component |
| `ILogger<\w+> _logger` | 8 | DI logging pattern |
| `def \w+(...) -> \w+:` | 8 | Python type hints |
| `useAppDispatch\|useAppSelector` | 8 | Redux typed hooks |
| `.unwrap().then(` | 12 | Redux async unwrap |

---

### Tier 4: Moderate Confidence (70-79%) — Weight: 4-7

Common modern patterns needing multiple matches:

| Pattern | Weight | Description |
|---------|--------|-------------|
| `??.`, `??=` | 5 | Null coalescing operators |
| `record \w+(` | 5 | C# record types |
| `IOptions<\w+>` | 4 | Options pattern |
| `AddScoped<T, T>` | 4 | DI registration |
| `interface \w+Props {` | 5 | React props interface |
| `useState<T>(` | 5 | Typed useState |
| `useEffect(() => {` | 5 | React effect hook |
| `Optional[\w+]` | 5 | Python Optional type |
| `@dataclass` | 5 | Python dataclass |
| `reducers: {` | 5 | Redux reducers |
| `export const \w+Slice =` | 7 | Redux slice export |

---

### Tier 5: Low Confidence (60-69%) — Weight: 2-3

Very common patterns needing many matches:

| Pattern | Weight | Description |
|---------|--------|-------------|
| `?.\w+` | 2 | Optional chaining |
| `??` | 2 | Null coalescing |
| `await \w+` | 2 | Basic await |
| `.map(\w+ =>` | 2 | Arrow function map |
| `.filter(\w+ =>` | 2 | Arrow function filter |
| `const \w+ = async` | 3 | Async arrow function |
| `@property` | 2 | Python property decorator |
| `f"..{var}.."` | 2 | Python f-strings |

---

## Scoring Algorithm

### Score Calculation

```
Total Score = Tier2Score + Tier3Score + Tier4Score + Tier5Score + CommitMessageScore
```

### Pattern Density

Pattern density ensures commits have sufficient AI patterns relative to their size:

```
Pattern Density = (Weighted Score / Total Added Lines) × 100
```

### Size Normalization

Large commits get reduced scores to prevent false positives:

| Commit Size | Size Factor |
|-------------|-------------|
| > 1000 lines | 0.5 (50% reduction) |
| > 500 lines | 0.7 (30% reduction) |
| < 10 lines | 0.6 (40% reduction) |

```
Normalized Score = Weighted Score × Size Factor
```

### Classification Thresholds

| Tier | Score Threshold | Min Density | Confidence Range |
|------|-----------------|-------------|------------------|
| Tier 2 | ≥ 40 | ≥ 2.0 | 90-98% |
| Tier 3 | ≥ 30 (or T2+T3 ≥ 35) | ≥ 2.0 | 80-89% |
| Tier 4 | ≥ 25 (or normalized ≥ 30) | ≥ 1.5 | 70-79% |
| Tier 5 | ≥ 15 (or normalized ≥ 20) | ≥ 1.0 | 60-69% |
| Human | Below thresholds | — | N/A |

---

## Exclusions

### Excluded File Types

Files that often produce false positives are excluded from pattern analysis:

- **Test files**: `.test.ts`, `.spec.js`, `_test.py`, `_test.go`
- **Test directories**: `tests/`, `__tests__/`
- **Mock files**: `.mock.`, `mock.*`
- **Configuration**: `jest.config`, `setup.py`, `conftest.py`
- **Generated**: `.d.ts`, `.min.js`
- **Lock files**: `package-lock.json`, `yarn.lock`
- **Storybook**: `.stories.`

### Excluded Commit Types

Commits automatically classified as human:

- **Merge commits**: `Merge branch`, `Merge pull`
- **Reverts**: `Revert "`
- **Documentation**: `Update *.md`
- **Version bumps**: `bump version`, `release v*`
- **Hotfixes**: `hotfix`
- **Cherry-picks**: `cherry-pick`

---

## Git Trailers (Definitive AI Detection)

The following Git trailers immediately classify a commit as Tier 1 AI-assisted:

```
Co-authored-by: Copilot
Co-authored-by: AI <ai@example.com>
Signed-off-by: Copilot
Generated-by: Copilot
AI-assisted: true
```

---

## Output Files

For each analysis run, the script generates:

| File | Description |
|------|-------------|
| `UserAnalysis_{Branch}_{timestamp}.csv` | Per-user statistics |
| `BranchAnalysis_{Branch}_{timestamp}.csv` | Branch-level summary |
| `FileTypeAnalysis_{Branch}_{timestamp}.csv` | AI usage by file type |
| `Analysis_{Branch}_{timestamp}.json` | Complete data with all commits |
| `Analysis_{Branch}_{timestamp}.md` | Human-readable report |

---

## Incremental Analysis

When `PreviousDataPath` is provided:

1. Loads previously analyzed commits from JSON
2. Fetches only new commits since last analysis
3. Deduplicates by commit hash
4. Merges results for comprehensive reporting
5. Preserves file type statistics

This enables efficient daily/scheduled analysis without re-processing entire history.

---

## Related Scripts

| Script | Description |
|--------|-------------|
| [Run-BatchAnalysis.ps1](RUN-BATCHANALYSIS.md) | Orchestrates analysis across multiple repositories |
| [Validate-GitAccess.ps1](../scripts/Validate-GitAccess.ps1) | Validates Git repository access before analysis |

---

*Documentation for Copilot Usage Report Tool*
